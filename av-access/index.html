<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Code4Lib 2016 - Access To Video Collections For The Bots in All of Us</title>

		<meta name="description" content="">
		<meta name="author" content="Drew Gordon">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="../css/reveal.css">
		<link rel="stylesheet" href="../css/theme/c4l.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="../lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? '../css/print/pdf.css' : '..//css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<div class="slides">
				<section data-background="">
					<h2 class="orange">Accessible Digital Video Libraries for Humans <span style="text-decoration: underline;">and</span> Machines</h2> 
					<h5 class="pink">Drew Gordon - Data Curator, Databrary Project</h5>
					<h6 class="mint">drew.gordon@nyu.edu</h5>
					<aside class="notes">
						My current work involves a lot of video, research video. Questions of delivering this video to other researchers for sharing involve how to provide access to the videos in the browser, but also how to generate and allow search on annotation on those videos for specific research purposes.
						<br/>
						This talk is more generally about modern and future needs for users (and machines)
						to access digital video assets over the Internet.
						<br/>
						The idea for this talk got started when I wanted to learn more about the DPLA API and how to make something interesting with it.
					</aside>
				</section>

				<section>
					<h3 class="lavender">Video In the DPLA</h3>
					<ul>
						<li class="fragment"> 27,099 Moving image items (Feb 2016)</li>
						<li class="fragment"> 17 Hubs </li>
						<li class="fragment">Standardized search, all in one place</li>
					</ul>
					<aside class="notes">
						Excited to take advantage of having all of this in one place. Perfect jump off point for performing an exploration across a large number of videos with archival value.
					</aside>

				</section>

				<section>
					<h3 class="lavender">Challenges to programatic access</h3>
					<ul>
						<li class="fragment">Not able to store derivatives locally</li>
						<li class="fragment">No consistent indication of resource location in metadata</li>
						<li class="fragment">Wide diversity of implementations for delivering access copies at host sites</li>
					</ul>
					<aside class="notes">
							Just to be clear, this is not an attack. It's a celebration of being able to get at such a range of collections all in one place. And it gives rise to challenges that we are very lucky to have.
						</aside>
				</section>

				<section>
					<img class="plain" src="images/video_counts.gif"/>
					<aside class="notes">
						Digital Library of Georgia and the National Arhives make up about 63% of total video objects in DPLA.

						Real long tail phenomena.
					</aside>
				</section>

				<section>
					<h3 class="mint">Some Questions</h3>
					<ul>
						<li class="fragment">For whom (and/or what) are we designing digital video libraries for?</li>
						<li class="fragment">Are we accounting for new, and unexpected uses that weren't conceivable 5 years ago?</li>
						<li class="fragment">How do we get there?</li>
						<aside class="notes">
							I don't have all the answers. I don't assume this is easy. I see this as an oppotunity to get more information from those who might know better than I.
						</aside>
					</ul>	
				</section>

				<section data-background="images/dogtv1.gif">
					<aside class="notes">
						Modes of production for videos have changed, so should modes of discovery and interaction
					</aside>
				</section>
				<section data-background="images/dogtv2.gif">
				</section>

				<section>

					<h2 class="pink">More to videos than just watching them</h2>
					<h5 class="fragment">...they're information too</h5>
					<aside class="notes">
							We should be invited to do with videos what we do with images and text: munge and manipulate, analyze and recombine...synthesize, build from.
						</aside>

				</section>

				<section data-background="">
						<h3 class="pink">Make a twitter bot. Sure why not?</h3>
						<img class="plain" src="https://imgs.xkcd.com/comics/twitter_bot.png"/>
						<a href="https://xkcd.com/1646/">https://xkcd.com/1646/</a>
						<aside class="notes">
							Like others, I wanted to write a bot that allowed me to do something interesting with the DPLA API. As indicated by the graphic here, in writing a bot, you often get more than what you originally bargained for. 
							<br/>
							Though while I ran into the typical problems. I want to talk here more about what the process of writing this bot taught me about the current state of accessing video collections -- with the hlp of a service like the DPLA -- and perhaps some ideas for improving access not only for humans, but machines as well.
						</aside>
				</section>

				<section data-background="">
					<h3 class="pink">Historical GIFs</h3>
					<h4><a href="https://twitter.com/dpladotgif" target="_blank">@dpladotgif</a></h4>
					<img class="plain" src="images/hist_gif_sloth.gif" style="width: 50%; height: 50%"/>
				</section>

				<section> 
					<h3 class="lavender">What's the deal with video?</h3>
					<ul>
						<li class="fragment">It's relatively massive</li>
						<li class="fragment">Restrictions and rights</li>
						<li class="fragment">Differences in digital Encodings and formats. Analog formats, too</li>
						<li class="fragment">It's information rich, but information that's difficult to search unless annotated and transcribed</li>
					</ul>
		
						<aside class="notes">
							Though where restrictions are concerned, it's heartening to know that over 99% of the 5640 items provided by the national archives are fully Unrestricted. Georgia seems ok too ( though certainly not unrestricted, but not all rigths reserved )

							The more video there is the less you'll be able to describe and facilitate access manually.
						</aside>
				</section>

				<section>
					<h3 class="mint">Findability (right now stuff)</h3>
					- generate thumbnail previews using FFMPEG streaming and Imagemagick
					- what Ronallo said, and schema.org?					
				</section>
				<section>
					<h3 class="mint">Reusability (future stuff)</h3>
					- open standards (no flash, no proprietary)
					- provide direct access to resource in api
					- allow services to connect to resources directly
				</section>
				
				<section>
					<h3 class="mint">Imagine the Possibilities</h3>
					<ul>
						<li class="fragment">Leverage nueral networks for automated metadata generation</li>
						<li class="fragment">Build around distribution, not centraliztion</li>
						<li class="fragment">Open Annotations</li>						
						<li class="fragment">Automated transcription from anywhere</li>
						<li class="fragment">Researchers with uninhibited access across institutions</li>
					</ul>
					<aside class="notes">
						Video will only be more and more, human work to desribe will not be enough.

						Sorry this is so sizzle and no steak, but these are challenging issues that may not truly become issues for many years, but why not start thinking about them now? Why not plan for them. A lot of smart people in this room working on projects arond this, building the infrastructure that many libraries will be implementing.

						I don't have the answers, of course, but I just wanted to talk about it because it interests me and I want to know what others have to say.
					</aside>
				</section>
				<section>
					<h3 class="orange">To summarize</h3> 
					<h5 class="skyblue fragment">Video is an amazing resource</h5> 
					<h5 class="skyblue fragment">But access to them is hemmed up</h5> 
					<h5 class="skyblue fragment">What will it take to redifine the distribution of video cultural heritage content to meet new information needs?</h5>
				</section>
				<section>
					<h2 class="skyblue">Thank You!</h2>
					<div class="raised">
						<h5 class="mint">drew.gordon@nyu.edu</h5>
						<h5 class="pink">@dogrdon</h5>
						<h5 class="orange"><a href="https://github.com/dogrdon/accidentalculture"></a>https://github.com/dogrdon/accidentalculture</h5>
						<aside class="notes">

						</aside>
					</div>
				</section>


			</div>

		</div>

		<script src="../lib/js/head.min.js"></script>
		<script src="../js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: '../lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: '../plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: '../plugin/zoom-js/zoom.js', async: true },
					{ src: '../plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
